install.packages("dslabs")
library(dslabs)
install.packages()
installed.packages()
install.packages("tidyverse")  # to install a single package
installed.packages()
library(tidyverse)
library(dslabs)
data("murders")
a<-1
b<-1
c<- -1
a
print(a)
ls()
(-b + sqrt(b^2 - 4*a*c))/(2*a)
a <- 2
b <- -1
c <- -4
(-b + sqrt(b^2 - 4*a*c))/(2*a)
a
(-b + sqrt(b^2 - 4*a*c))/(2*a)
(-b - sqrt(b^2 - 4*a*c))/(2*a)
log4(1024)
log(1024, base=4)
data("movielens")
str(movielens)
nlevels(movielens$genres)
x <- c(31, 4, 15, 92, 65)
x
sort(x)    # puts elements in order
index <- order(x)    # returns index that will put x in order
x[index]    # rearranging by this index puts elements in order
order(x)
index
x <- c(2, 43, 27, 96, 18)
sort(x)
order(x)
rank(x)
which.max(x)
max(x)
name <- c("Mandi", "Amy", "Nicole", "Olivia")
distance <- c(0.8, 3.1, 2.8, 4.0)
time <- c(10, 30, 40, 50)
tim <- time/60
time <- time/60
time
distance/time
library.load(murders)
library(dslabs)
data("murders")
# defining murder rate as before
murder_rate <- murders$total / murders$population * 100000
# creating a logical vector that specifies if the murder rate in that state is less than or equal to 0.71
index <- murder_rate <= 0.71
# determining which states have murder rates less than or equal to 0.71
murders$state[index]
# calculating how many states have a murder rate less than or equal to 0.71
sum(index)
# creating the two logical vectors representing our conditions
west <- murders$region == "West"
safe <- murder_rate <= 1
# defining an index and identifying states with both conditions true
index <- safe & west
murders$state[index]
a <- c(3,2,1,6,5)
rank(a)
order(a)
x <- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)
which(x)    # returns indices that are TRUE
# to determine the murder rate in Massachusetts we may do the following
index <- which(murders$state == "Massachusetts")
index
murder_rate[index]
# to obtain the indices and subsequent murder rates of New York, Florida, Texas, we do:
index <- match(c("New York", "Florida", "Texas"), murders$state)
index
murders$state[index]
murder_rate[index]
x <- c("a", "b", "c", "d", "e")
y <- c("a", "d", "f")
y %in% x
# to see if Boston, Dakota, and Washington are states
c("Boston", "Dakota", "Washington") %in% murders$state
install.packages("dplyr")
library(dplyr)
# adding a column with mutate
library(dslabs)
data("murders")
murders <- mutate(murders, rate = total / population * 100000)
# subsetting with filter
filter(murders, rate <= 0.71)
# selecting columns with select
new_table <- select(murders, state, region, rate)
# using the pipe
murders %>% select(state, region, rate) %>% filter(rate <= 0.71)
# creating a data frame with stringAsFactors = FALSE
grades <- data.frame(names = c("John", "Juan", "Jean", "Yao"),
exam_1 = c(95, 80, 90, 85),
exam_2 = c(90, 85, 85, 90),
stringsAsFactors = FALSE)
library(dslabs)
data(heights)
options(digits = 3)
str(heights)
mean(heights$heights)
mean(heights$height)
ind <- heights$height < 68.3
ind
sum(ind)
ind <- heights$height > 68.3
sum(ind)
str(heights)
ind <- heights$height > 68.3 & heights$sex = "Female"
ind <- heights$height > 68.3 & heights$sex == "Female"
sum(ind)
mean(heights$sex == "Female")
min(heights$height)
help("match")
match(50, heights$height)
heights$sex[1032]
max(heights$height)
min(heights$height)
x <- 50:82
which(x == heights$height)
which(x %in% heights$height)
which(heights$height %in% x)
sum(x ! %in% heights$height)
sum(! x %in% heights$height)
heights <- mutate(heights, ht_cm = height*2.54)
cm <- heights$ht_cm
cm[18]
mean(cm)
heights2<- heights
females <- heights2 %>% filter(sex == "Female")
females
mean(females$ht_cm)
library(dslabs)
data(olive)
head(olive)
plot(olive$palmitic, olive$palmitoleic)
histogram(olive$eicosenoic)
hist(olive$eicosenoic)
boxplot(palmitic~region, olive)
# an example showing the general structure of an if-else statement
a <- 0
if(a!=0){
print(1/a)
} else{
print("No reciprocal for 0.")
}
# an example that tells us which states, if any, have a murder rate less than 0.5
library(dslabs)
data(murders)
murder_rate <- murders$total / murders$population*100000
ind <- which.min(murder_rate)
if(murder_rate[ind] < 0.5){
print(murders$state[ind])
} else{
print("No state has murder rate that low")
}
# changing the condition to < 0.25 changes the result
if(murder_rate[ind] < 0.25){
print(murders$state[ind])
} else{
print("No state has a murder rate that low.")
}
# the ifelse() function works similarly to an if-else conditional
a <- 0
ifelse(a > 0, 1/a, NA)
# the ifelse() function is particularly useful on vectors
a <- c(0,1,2,-4,5)
result <- ifelse(a > 0, 1/a, NA)
# the ifelse() function is also helpful for replacing missing values
data(na_example)
no_nas <- ifelse(is.na(na_example), 0, na_example)
sum(is.na(no_nas))
# the any() and all() functions evaluate logical vectors
z <- c(TRUE, TRUE, FALSE)
any(z)
all(z)
# example of defining a function to compute the average of a vector x
avg <- function(x){
s <- sum(x)
n <- length(x)
s/n
}
# we see that the above function and the pre-built R mean() function are identical
x <- 1:100
identical(mean(x), avg(x))
# variables inside a function are not defined in the workspace
s <- 3
avg(1:10)
s
# the general form of a function
my_function <- function(VARIABLE_NAME){
perform operations on VARIABLE_NAME and calculate VALUE
VALUE
}
# functions can have multiple arguments as well as default values
avg <- function(x, arithmetic = TRUE){
n <- length(x)
ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))
}
# creating a function that computes the sum of integers 1 through n
compute_s_n <- function(n){
x <- 1:n
sum(x)
}
# a very simple for-loop
for(i in 1:5){
print(i)
}
# a for-loop for our summation
m <- 25
s_n <- vector(length = m) # create an empty vector
for(n in 1:m){
s_n[n] <- compute_s_n(n)
}
# creating a plot for our summation function
n <- 1:m
plot(n, s_n)
# a table of values comparing our function to the summation formula
head(data.frame(s_n = s_n, formula = n*(n+1)/2))
# overlaying our function with the summation formula
plot(n, s_n)
lines(n, n*(n+1)/2)
2.113208 - 2.150943
1.496855 - 2.050314
## WEEK 5 LAB
## Load packages via 'pacman' package manager
pacman::p_load(dplyr, purrr)
## Download and import from the web (or download manually)
url.zip <- "https://osf.io/fv8c3/download" # Download location
file.zip <- "1. Crowdsourcing Dataset July 01, 2014 Incl.Ref Country.zip" # File name
if (!file.exists(file.zip)) # If the file is not in the working directory...
download.file(url = url.zip, destfile = file.zip, mode = "wb") # ...then download the file
file.csv <- grep("csv", unzip(file.zip),
ignore.case = TRUE, value = TRUE) # Unzip and grab filename
fb <- read.csv(file.csv[1]) # Load the data
# QUESTION 1
head(fb) # Check the data
names(fb) # List variables
View(fb)
ycards <- aggregate(yellowCards ~ playerShort, sum, data = fb)
yrcards <- aggregate(yellowReds ~ playerShort, sum, data = fb)
rcards <- aggregate(redCards ~ playerShort, sum, data = fb)
games <- aggregate(games ~ playerShort, sum, data = fb)
## Predictor variable - mean ratings
tone1 <- aggregate(rater1 ~ playerShort, mean, data = fb)
tone2 <- aggregate(rater2 ~ playerShort, mean, data = fb)
tone1
View(fb)
## Merge the datasets using the 'left_join()' function from 'tidyverse'
fb.wide <- list(ycards, yrcards, rcards, games, tone1, tone2) %>%
reduce(left_join, by = "playerShort")
View(fb.wide)
fb.wide$avg.tone <- (fb.wide$rater1 + fb.wide$rater2)/2
summary(fb.wide$avg.tone)
## Rate of any yellow or red card per 100 games
fb.wide$rate <- (fb.wide$yellowCards + fb.wide$yellowReds + fb.wide$redCards)/fb.wide$games * 100
summary(fb.wide$rate)
hist(fb.wide$rate, breaks = 20,
xlab = "Penalty Rate (per 100 games)",
main = "Distribution of Penalty Rate")
## Regression model - any penalty rate
model.1 <- lm(rate ~ avg.tone, data = fb.wide)
summary(model.1)
## Rate of only red cards per 100 games
fb.wide$rate2 <- fb.wide$redCards/fb.wide$games * 100
summary(fb.wide$rate2)
## Distribution of red cards
hist(fb.wide$rate2, breaks = 20,
xlab = "Red Card Rate (per 100 games)",
main = "Distribution of Red Card Rate")
## Regression model 2 - red card rate
model.2 <- lm(rate2 ~ avg.tone, data = fb.wide)
summary(model.2)
summary(model.1)
summary(fb.wide$rate2)
model.2 <- lm(rate2 ~ avg.tone, data = fb.wide)
summary(model.2)
fb.wide2 <- fb %>%
group_by(playerShort) %>%
summarise(games = sum(games),
victories = sum(victories),
ties = sum(ties),
defeats = sum(defeats),
goals = sum(goals),
yellowCards = sum(yellowCards),
yellowReds = sum(yellowReds),
redCards = sum(redCards),
rater1 = mean(rater1), # Note that we use 'mean' here
rater2 = mean(rater2) # because it's one value per player
)
load("Exercise5.RData")
ls()
mydata = .getdata(200258713)
dim(mydata)
summary(mydata)
quantile(mydata$attainment)
mydata$attainment2 = cut(mydata$attainment, c(23.90,26.80,27.80,28.55,33.50), c(1,2,3,4) )
mydata$attainment2 = as.numeric(mydata$attainment2)
plot(attainment2 ~ fsm, data=mydata)
firstlm = lm(attainment2 ~ fsm, data= mydata)
summary(firstlm)
abline(firstlm)
plot(firstlm,which= c(1,3,5))
install.packages("ordinal")
library(ordinal)
mydata$attainment2 = as.factor(mydata$attainment2)
m1 <- clm(attainment2~fsm, data=mydata)
summary(m1)
exp(-10.2772)
exp(coef(m1))
m2 <- clm(attainment2 ~ 1, nominal=~fsm, data=mydata)
summary(m2)
anova(m1, m2)
m3 <- clm(attainment2 ~ fsm + white + indian +
chinese + blk.car + blk.afr + coe + rc , data=mydata)
summary(m3)
setwd("~/Documents/Manchester Module/Formative Assessment/udate")
linked = read.csv('cleaned.csv')
library(mice)
newlinked <- linked[-574, -c(1,2,3,4)]
imp <- mice(newlinked,m=5,maxit=10, seed=500)
imp <- mice(newlinked,m=5,maxit=30, seed=500)
md.pattern(complete(imp))
imp$data$socioecindex <- imp$data$Noqual + imp$data$hhSocialRented + imp$data$JobSeekers
md.pattern(complete(imp))
library(TAM)
library(miceadds)
# convert into datlist
datlist <- miceadds::mids2datlist(tempData)
# select the numeric variables we want to standardise
vars <- c('Crimerate', 'hhSocialRented', 'JobSeekers',
'Noqual', 'nonwhite', 'NotEnglishspeaking',
'LifeExpectancy')
sdatlist <- miceadds::scale_datlist( datlist=datlist, orig_var = vars, trafo_var=paste0("z",vars))
datlist <- miceadds::mids2datlist(tempData)
# convert into datlist
datlist <- miceadds::mids2datlist(imp)
sdatlist <- miceadds::scale_datlist( datlist=datlist, orig_var = vars, trafo_var=paste0("z",vars))
imp2 <- miceadds::datlist2mids(sdatlist)
modelfit1 <- with(imp2, lm(zMalelifeexpectancy~ zCrimerate + zhhSocialRented + zJobSeekers +
zNoqual + znonwhite + zNotEnglishspeaking + Wardcode))
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + zhhSocialRented + zJobSeekers +
zNoqual + znonwhite + zNotEnglishspeaking ))
summary(pool(modelfit1))
imp$data$socioecindex <- (imp$data$Noqual + imp$data$hhSocialRented + imp$data$JobSeekers)/3
vars <- c('Crimerate', 'hhSocialRented', 'JobSeekers',
'Noqual', 'nonwhite', 'NotEnglishspeaking',
'LifeExpectancy', 'socioecindex')
datlist <- miceadds::mids2datlist(imp)
sdatlist <- miceadds::scale_datlist( datlist=datlist, orig_var = vars, trafo_var=paste0("z",vars))
imp2 <- miceadds::datlist2mids(sdatlist)
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + zhhSocialRented + zJobSeekers +
zNoqual + znonwhite + zNotEnglishspeaking ))
summary(pool(modelfit1))
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + zhhSocialRented + zJobSeekers +
zNoqual + znonwhite + zNotEnglishspeaking + zsocioecindex))
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate +
znonwhite + zNotEnglishspeaking + zsocioecindex))
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + znonwhite + zNotEnglishspeaking + zsocioecindex))
vars <- c('Crimerate', 'hhSocialRented', 'JobSeekers',
'Noqual', 'nonwhite', 'NotEnglishspeaking',
'LifeExpectancy', 'socioecindex')
sdatlist <- miceadds::scale_datlist( datlist=datlist, orig_var = vars, trafo_var=paste0("z",vars))
imp2 <- miceadds::datlist2mids(sdatlist)
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + znonwhite + zNotEnglishspeaking + zsocioecindex))
md.pattern(complete(imp))
apply(complete(imp), 2, function(x) any(is.na(x)))
which(is.na(as.numeric(as.character(imp))))
which(is.na(imp))
modelfit1 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + zhhSocialRented + zJobSeekers +
zNoqual + znonwhite + zNotEnglishspeaking))
modelfit2 <- with(imp2, lm(zLifeExpectancy~ zCrimerate + znonwhite + zNotEnglishspeaking + zsocioecindex))
summary(pool(modelfit1))
modelfit2 <- with(imp2, lm(zLifeExpectancy~ zCrimerate  + zNotEnglishspeaking + zsocioecindex))
md.pattern(complete(imp))
long <- mice::complete(imp, "long", include = TRUE)
long$socioecindex <- with(long, (Noqual + hhSocialRented + JobSeekers) / 3)
imp.itt <- as.mids(long)
md.pattern(complete(imp.itt))
sdatlist <- miceadds::scale_datlist( datlist=datlist, orig_var = vars, trafo_var=paste0("z",vars))
# row 574 has most NAs. We delete these
max(na_rows)
na_rows = rowSums(is.na(linked))
which.max(na_rows)
max(na_rows)
newlinked <- linked[-574, -c(1,2,3,4)]
md.pattern(newlinked)
library(VIM)
# Read in the linked dataset and check its format.
linked = read.csv('cleaned.csv')
head(linked)
# Load the mice library and check where the missing values are.
library(mice)
md.pattern(linked)
library(VIM)
aggr_plot <- aggr(linked, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(linked), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
# Number of NA values in each row:
na_rows = rowSums(is.na(linked))
# Find which row has the most na values
which.max(na_rows)
max(na_rows)
# Row 574 has most NAs.
# Delete row 574 and the categorical columns
# as we don't want to include dummy variables
# (linear combinations of each other)
newlinked <- linked[-574, -c(1,2,3,4)]
# Check what methods are available for imputing data.
methods(mice)
